{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os; os.environ['CUDA_VISIBLE_DEVICES'] = sys.argv[1]\n",
    "import numpy as np\n",
    "from data import ImageSegmentationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from model import ImgSegRefExpModel\n",
    "\n",
    "\n",
    "def load_vocab_dict_from_file(dict_file):\n",
    "    with open(dict_file) as f:\n",
    "        words = [w.strip() for w in f.readlines()]\n",
    "    vocab_dict = {words[n]:n for n in range(len(words))}\n",
    "    return vocab_dict\n",
    "\n",
    "#Util functions\n",
    "\n",
    "# # all boxes are [num, height, width] binary array\n",
    "def compute_mask_IU(masks, target):\n",
    "    #print (np.sum(np.logical_and(masks, target)))\n",
    "    assert(target.shape[-2:] == masks.shape[-2:])\n",
    "    I = torch.sum(np.logical_and(masks, target))\n",
    "    U = torch.sum(np.logical_or(masks, target))\n",
    "    return I, U\n",
    "\n",
    "def resize_and_pad(im, input_h, input_w):\n",
    "    # Resize and pad im to input_h x input_w size\n",
    "    im_h, im_w = im.shape[:2]\n",
    "    scale = min(input_h / im_h, input_w / im_w)\n",
    "    resized_h = int(np.round(im_h * scale))\n",
    "    resized_w = int(np.round(im_w * scale))\n",
    "    pad_h = int(np.floor(input_h - resized_h) / 2)\n",
    "    pad_w = int(np.floor(input_w - resized_w) / 2)\n",
    "\n",
    "    resized_im = skimage.transform.resize(im, [resized_h, resized_w])\n",
    "    if im.ndim > 2:\n",
    "        new_im = np.zeros((input_h, input_w, im.shape[2]), dtype=resized_im.dtype)\n",
    "    else:\n",
    "        new_im = np.zeros((input_h, input_w), dtype=resized_im.dtype)\n",
    "    new_im[pad_h:pad_h+resized_h, pad_w:pad_w+resized_w, ...] = resized_im\n",
    "\n",
    "    return new_im\n",
    "\n",
    "def resize_and_crop(im, input_h, input_w):\n",
    "    # Resize and crop im to input_h x input_w size\n",
    "    im_h, im_w = im.shape[:2]\n",
    "    scale = max(input_h / im_h, input_w / im_w)\n",
    "    resized_h = int(np.round(im_h * scale))\n",
    "    resized_w = int(np.round(im_w * scale))\n",
    "    crop_h = int(np.floor(resized_h - input_h) / 2)\n",
    "    crop_w = int(np.floor(resized_w - input_w) / 2)\n",
    "\n",
    "    resized_im = skimage.transform.resize(im, [resized_h, resized_w])\n",
    "    if im.ndim > 2:\n",
    "        new_im = np.zeros((input_h, input_w, im.shape[2]), dtype=resized_im.dtype)\n",
    "    else:\n",
    "        new_im = np.zeros((input_h, input_w), dtype=resized_im.dtype)\n",
    "    new_im[...] = resized_im[crop_h:crop_h+input_h, crop_w:crop_w+input_w, ...]\n",
    "\n",
    "    return new_im\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################\n",
    "# Parameters\n",
    "################################################################################\n",
    "\n",
    "root = '/home/nishaddawkhar/text_objseg/exp-referit/'\n",
    "\n",
    "image_dir = root + 'referit-dataset/images/'\n",
    "mask_dir = root + 'referit-dataset/mask/'\n",
    "query_file = root + 'data/referit_query_test.json'\n",
    "bbox_file = root + 'data/referit_bbox.json'\n",
    "imcrop_file = root + 'data/referit_imcrop.json'\n",
    "imsize_file = root + 'data/referit_imsize.json'\n",
    "vocab_file = root + 'data/vocabulary_referit.txt'\n",
    "\n",
    "query_file_val = root + 'data/referit_query_val.json'\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = ImageSegmentationDataset(query_file, image_dir, mask_dir)\n",
    "val_dataset = ImageSegmentationDataset(query_file_val, image_dir, mask_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6dd4018824f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimage_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mimage_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                (plugin, kind))\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mpil_to_ndarray\u001b[0;34m(image, dtype, img_num)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# this will raise an IOError if the file is not readable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://pillow.readthedocs.org/en/latest/installation.html#external-libraries\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mgetdata\u001b[0;34m(self, band)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \"\"\"\n\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetband\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#saving image sizes\n",
    "query_dict = json.load(open(query_file))\n",
    "\n",
    "image_names = set()\n",
    "for key, value in query_dict.items():\n",
    "    image_names.add(key.split('_')[0])\n",
    "\n",
    "import skimage.io\n",
    "image_sizes = {}\n",
    "for name in image_names:\n",
    "    im = skimage.io.imread(image_dir + name + '.jpg')\n",
    "    image_sizes[name] = im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "# trained model\n",
    "pretrained_model_file = \"/home/nishaddawkhar/text_objseg_pretrained_torch_converted_with_lstm.dms\"\n",
    "vocab_file = './vocabulary_referit.txt'\n",
    "\n",
    "# Load vocabulary\n",
    "vocab_dict = load_vocab_dict_from_file(vocab_file)\n",
    "\n",
    "# Load model and weights\n",
    "model = ImgSegRefExpModel(mlp_hidden=500, vocab_size=8803, emb_size=1000, lstm_hidden_size=1000)\n",
    "model.to(device)\n",
    "pre_trained = torch.load(pretrained_model_file)\n",
    "model.load_state_dict(pre_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 1879\tBatch Size: 32\tDataset size: 60105\n",
      "torch.Size([32, 1000, 16, 16])\n",
      "16 16\n",
      "Batch #0: Loss = 0.510920524597168\tAvg Loss: 0.005109205245971684\tTime: 77.4638831615448s\n",
      "torch.Size([32, 1000, 16, 16])\n",
      "16 16\n",
      "torch.Size([32, 1000, 16, 16])\n",
      "16 16\n",
      "torch.Size([32, 1000, 16, 16])\n",
      "16 16\n",
      "torch.Size([32, 1000, 16, 16])\n",
      "16 16\n",
      "torch.Size([32, 1000, 16, 16])\n",
      "16 16\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "# Model Params\n",
    "T = 20\n",
    "N = 10\n",
    "input_H = 512; featmap_H = (input_H // 32)\n",
    "input_W = 512; featmap_W = (input_W // 32)\n",
    "num_vocab = 8803\n",
    "embed_dim = 1000\n",
    "lstm_dim = 1000\n",
    "mlp_hidden_dims = 500\n",
    "\n",
    "#Training Params\n",
    "pos_loss_mult = 1.\n",
    "neg_loss_mult = 1.\n",
    "\n",
    "start_lr = 0.01\n",
    "lr_decay_step = 10000\n",
    "lr_decay_rate = 0.1\n",
    "weight_decay = 0.0005\n",
    "momentum = 0.9\n",
    "max_iter = 30000\n",
    "\n",
    "fix_convnet = False\n",
    "vgg_dropout = False\n",
    "mlp_dropout = False\n",
    "vgg_lr_mult = 1.\n",
    "\n",
    "cls_loss_avg = 0\n",
    "avg_accuracy_all, avg_accuracy_pos, avg_accuracy_neg = 0, 0, 0\n",
    "decay = 0.99\n",
    "\n",
    "# Combine weight decay regularisation with optimiser\n",
    "optimiser = torch.optim.SGD(model.parameters(),lr=start_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "torch.optim.lr_scheduler.StepLR(optimiser, step_size=lr_decay_step, gamma=lr_decay_rate)\n",
    "loss = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor(int(pos_loss_mult),int(neg_loss_mult)).to(device))\n",
    "\n",
    "for n_iter in range(max_iter):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    print(\"Number of batches: {}\\tBatch Size: {}\\tDataset size: {}\".format(len(train_loader),train_loader.batch_size,len(train_loader.dataset)))\n",
    "    cls_loss_avg = 0.0\n",
    "    for batchId,(image, text, gt_mask, original_image_name) in enumerate(train_loader):\n",
    "        optimiser.zero_grad()\n",
    "        batch_start = time.time()\n",
    "        text = text.long()\n",
    "        output_mask = model((image.to(device), text.to(device)))\n",
    "        output_mask = output_mask.squeeze(1)\n",
    "        cls_loss_val = loss(output_mask,gt_mask.float())\n",
    "        cls_loss_val.backward()\n",
    "        cls_loss_avg = decay*cls_loss_avg + (1-decay)*cls_loss_val.item()\n",
    "        optimiser.step()\n",
    "        if batchId % 100 == 0:\n",
    "            print(\"Batch #{}: Loss = {}\\tAvg Loss: {}\\tTime: {}s\".format(batchId,cls_loss_val.item(),cls_loss_avg,time.time()-batch_start))\n",
    "    print('\\titer = {},  Batch Loss (avg) = {}, lr = {}, time = {}s'.format(n_iter, cls_loss_avg, get_lr(optimiser),time.time()-start))\n",
    "    \n",
    "print('Optimization done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
